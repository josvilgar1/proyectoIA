{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as random\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializeRMatrix(numRows, numCols):\n",
    "    return np.array([-1 for _ in range((numRows**2)*(numCols**2))]).reshape(numRows**2, numCols**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¿Cuál es el tamaño del problema?  5\n"
     ]
    }
   ],
   "source": [
    "size = int(input('¿Cuál es el tamaño del problema? '))\n",
    "num_col = size\n",
    "num_fil = size\n",
    "states = (num_col*num_fil)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¿Cuál es el estado objetivo? 9\n"
     ]
    }
   ],
   "source": [
    "objetivo = int(input('¿Cuál es el estado objetivo?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo del tablero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos la Matriz tablero primero. Para ello, según hemos observado en el ejemplo, lo valores del tablero se incrementan por lo que hemos denominado __capas__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    -Capa 0: \n",
    "            [0]\n",
    "    -Capa 1: \n",
    "            [0  3]\n",
    "            [1  2]\n",
    "    -Capa 2:\n",
    "            [0  3  8]\n",
    "            [1  2  7]\n",
    "            [4  5  6]\n",
    "    -Capa 3: \n",
    "            [ 0   3   8  15]\n",
    "            [ 1   2   7  14]\n",
    "            [ 4   5   6  13]\n",
    "            [ 9  10  11  12]\n",
    "    -Capa n:\n",
    "            [ 0      3      8     15    .  (n^2)+2n  ]\n",
    "            [ 1      2      7     14    .  (n^2)+2n-1]\n",
    "            [ 4      5      6     13    .  (n^2)+2n-2]\n",
    "            [ 9     10     11     12    .  (n^2)+2n-3]\n",
    "              .      .      .      .    .      .\n",
    "            [n^2 (n^2)+1 (n^2)+2 (n^2)+3.    (n^2)+n ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para su simplificación, hemos decidido cambiar la orientación propuesta en el enunciado del problema. Los resultados obtenidos en la matriz Q no van a variar de ninguna forma, lo único es que la matriz obtenida estaría desplazada __90º__ respecto de la original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para modular el código hemos separado la función que ejecuta el bucle __n__ veces (n = número de capas que queramos en la matriz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrix(m,tam):\n",
    "    layer=0\n",
    "    for i in range(tam):\n",
    "        [m,layer]=addLayerToMatrix(m,i,layer)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la función que añade una capa más a la matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLayerToMatrix(matrix, layer, count):\n",
    "    for i in range(layer):\n",
    "        \n",
    "        matrix[layer][i] = int(count)\n",
    "        count=count+1\n",
    "        \n",
    "    for i in range(layer+1):\n",
    "        \n",
    "        matrix[layer-i][layer] = int(count)\n",
    "        count=count+1\n",
    "    \n",
    "    return [matrix, count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De ahí procedemos a crear el tablero deseado según el valor que hayamos introducido al principio del documento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3  8 15 24]\n",
      " [ 1  2  7 14 23]\n",
      " [ 4  5  6 13 22]\n",
      " [ 9 10 11 12 21]\n",
      " [16 17 18 19 20]]\n"
     ]
    }
   ],
   "source": [
    "zeroMatrix= np.zeros((num_fil,num_col))\n",
    "tablero = createMatrix(zeroMatrix,size).astype(int)\n",
    "print(tablero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de la matriz R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creado el tablero procederemos al calculo de la matriz R. Para ello nos basaremos en las posiciones de la matriz tablero. En esta ocasión los únicos movimientos válidos son los movimientos perpendiculares y diagonales. \n",
    "\n",
    "Para que la matriz obtenida no tenga en cuenta los espacios fuera del tablero, tenemos que controlar los movimientos en los bordes del tablero. Dicho de otra forma controlamos cuando cualquiera de los índices del bucle se encuentra en la posición 0 o en la posición máxima menos 1.\n",
    "\n",
    "Cuando los índices se encuentren entre los valores mencionados en el párrafo anterior no existe restricción, menos que no puede ir a sí mismo. Esto último lo hemos decidido para que el entrenamiento de la matriz Q se ejecute de la forma más rápido posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este método obtiene automáticamente la Matriz R a partir del tablero (m) introducido por el usuario\n",
    "def obtainRMatrix(m):\n",
    "    Rsize = size**2\n",
    "    rMatrix = inicializeRMatrix(num_col,num_fil)\n",
    "    res=[]\n",
    "    for i in range(num_fil):\n",
    "        for j in range(num_col):\n",
    "            n0 = m[i][j]\n",
    "            if 0<i<num_fil-1:\n",
    "                rMatrix[m[i][j]][m[i-1][j]]=0\n",
    "                rMatrix[m[i][j]][m[i+1][j]]=0\n",
    "                \n",
    "                if(0<j<num_col-1):\n",
    "                    rMatrix[m[i][j]][m[i-1][j-1]]=0\n",
    "                    rMatrix[m[i][j]][m[i][j-1]]=0\n",
    "                    rMatrix[m[i][j]][m[i-1][j+1]]=0\n",
    "                    rMatrix[m[i][j]][m[i+1][j-1]]=0\n",
    "                    rMatrix[m[i][j]][m[i+1][j+1]]=0\n",
    "                    rMatrix[m[i][j]][m[i][j+1]]=0\n",
    "                    \n",
    "                if(j==0):\n",
    "                    rMatrix[m[i][j]][m[i-1][j+1]]=0\n",
    "                    rMatrix[m[i][j]][m[i][j+1]]=0\n",
    "                    rMatrix[m[i][j]][m[i+1][j+1]]=0\n",
    "                    \n",
    "                if(j==num_col-1):\n",
    "                    rMatrix[m[i][j]][m[i-1][j-1]]=0\n",
    "                    rMatrix[m[i][j]][m[i][j-1]]=0\n",
    "                    rMatrix[m[i][j]][m[i+1][j-1]]=0  \n",
    "                    \n",
    "            elif(i==0):\n",
    "                rMatrix[m[i][j]][m[i+1][j]]=0             \n",
    "                \n",
    "                if(j==0):\n",
    "                    rMatrix[m[i][j]][m[i+1][j+1]]=0             \n",
    "                    rMatrix[m[i][j]][m[i][j+1]]=0   \n",
    "                    \n",
    "                if(j==num_col-1):\n",
    "                    rMatrix[m[i][j]][m[i+1][j-1]]=0  \n",
    "                    rMatrix[m[i][j]][m[i][j-1]]=0 \n",
    "                    \n",
    "                if(0<j<num_col-1):\n",
    "                    rMatrix[m[i][j]][m[i+1][j-1]]=0  \n",
    "                    rMatrix[m[i][j]][m[i+1][j+1]]=0  \n",
    "                    rMatrix[m[i][j]][m[i][j+1]]=0  \n",
    "                    rMatrix[m[i][j]][m[i][j-1]]=0  \n",
    "                    \n",
    "            elif i==num_fil-1:\n",
    "                rMatrix[m[i][j]][m[i-1][j]]=0  \n",
    "                if(j==0):\n",
    "                    rMatrix[m[i][j]][m[i-1][j+1]]=0  \n",
    "                    rMatrix[m[i][j]][m[i][j+1]]=0  \n",
    "                if(j==num_col-1):\n",
    "                    rMatrix[m[i][j]][m[i-1][j-1]]=0  \n",
    "                    rMatrix[m[i][j]][m[i][j-1]]=0  \n",
    "                if(0<j<num_col-1):\n",
    "                    rMatrix[m[i][j]][m[i-1][j+1]]=0  \n",
    "                    rMatrix[m[i][j]][m[i-1][j-1]]=0  \n",
    "                    rMatrix[m[i][j]][m[i][j+1]]=0  \n",
    "                    rMatrix[m[i][j]][m[i][j-1]]=0  \n",
    "    return rMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creada la función necesitamos añadirle el estado objetivo. Para ello hemos creado la funcion addOjetives. Aunque en este caso únicamente le añadimos sólo un objetivo, hemos implementado la opción de que se le puedan añadir varios objetivos.\n",
    "\n",
    "La forma de hacerlo es simple. Todos los estados que lleven hacia los estados objetivo tendrán una recompensa mayor que un estado intermedio. Para ello tenemos que modificar los elementos de la columna del estado objetivo en la matriz R. Específicamente cambiaremos los elementos que se correspondan con acciones posibles (recompensa 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addObjetives(R,objetives):\n",
    "    for objetive in objetives:\n",
    "        for i in range(num_fil**2):\n",
    "            R[i][objetive] = 100 if (R[i][objetive]==0) else -1       \n",
    "        R[objetive][objetive] = 100\n",
    "    return R          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así obtenemos la matriz R final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "rMatrix=obtainRMatrix(tablero)\n",
    "rMatrix=addObjetives(rMatrix,[objetivo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo de aprendizaje \n",
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este apartado es el núcleo de nuestro proyeco. El momento en el que el algoritmo aprende y optimiza el camino hacia el objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello, primero inicializamos la matriz __Q__ con todos sus valores a 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "qMatrix = np.zeros((size**2,size**2)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente prodecemos al entrenamiento de la matriz __Q__. Para ello, como podemos ver en el método __entrenarQ__. De entrada necesitamos los elementos anteriormente calculados: matriz R, matriz Q, además de el número Gamma, el objetivo (obtenido al principio del documento), y el número de episodios que queremos que el algoritmo ejecute de entrenamiento. \n",
    "\n",
    "Un __episodio__ abarca desde que el agente se encuentra en el __estado inicial__ hasta que encuentra el __estado objetivo__.\n",
    "Por lo tanto, nos es dificil pensar que cuantos más episodios introduzcamos, mejor se va a entrenar el algoritmo. Esta asunción no esta alejada de la realidad, pero no tiene en cuenta que pasados un número de episodios la matriz __Q__ no se modifica, por lo tanto el algoritmo no mejora el aprendimiento. Esto nos lleva a pensar que este aprendimiento es asintótico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarQ ( Q, R, Gamma, objetivo, num_episodios ):\n",
    "    while num_episodios > 0:\n",
    "        estado = random.randint ( 0, num_fil**2 - 1 )\n",
    "        while ( estado != objetivo ):\n",
    "            #acciones = acciones ( R, estado )\n",
    "            accion_elegida = random.choice ( acciones ( R, estado ) )\n",
    "            siguiente_estado = accion_elegida\n",
    "            Q [ estado, accion_elegida ] = R [ estado, accion_elegida ] + Gamma * maxQValue(Q,R,siguiente_estado)\n",
    "            estado = siguiente_estado\n",
    "        num_episodios = num_episodios - 1\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la ejecución del método __entrenarQ()__ hacemos uso de dos métodos diferentes: __maxValue()__ y __acciones()__. El primero obtiene el valor máximo dentro de las acciones posibles dentro de un estado, y el segundo obtiene las acciones posibles dentro de un estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxQValue(Q, R, estado):\n",
    "    #obtener los estados accesibles desde la matriz R\n",
    "    rRow = R[estado]\n",
    "    qRow = Q[estado]\n",
    "    possibleStatesIndex = np.where(rRow != -1)\n",
    "    #obtener los valores en la matriz Q\n",
    "    qLista=qRow[possibleStatesIndex]\n",
    "    #devolver el máximo\n",
    "    maxValue=np.amax(qLista)\n",
    "    return maxValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acciones ( matriz, estado ):\n",
    "    fila_estado = matriz [ estado , : ]\n",
    "    acciones = [ ]\n",
    "    for n in range ( len ( fila_estado ) ):\n",
    "        if (fila_estado [ n ] != -1):\n",
    "            acciones.append(n)\n",
    "    return (acciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a entrenar la matriz __Q__: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.  ,  64.  ,  64.  ,  51.2 ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [ 51.2 ,   0.  ,  64.  ,  51.2 ,  80.  ,  80.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [ 51.2 ,  64.  ,   0.  ,  51.2 ,  80.  ,  80.  ,  64.  ,  64.  ,\n",
       "         51.2 ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [ 51.2 ,  64.  ,  64.  ,   0.  ,   0.  ,   0.  ,   0.  ,  64.  ,\n",
       "         51.2 ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,  64.  ,  64.  ,   0.  ,   0.  ,  80.  ,   0.  ,   0.  ,\n",
       "          0.  , 100.  ,  80.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,  64.  ,  64.  ,   0.  ,  80.  ,   0.  ,  64.  ,  64.  ,\n",
       "          0.  , 100.  ,  80.  ,  64.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,  64.  ,   0.  ,   0.  ,  80.  ,   0.  ,  64.  ,\n",
       "          0.  ,   0.  ,  80.  ,  64.  ,  51.2 ,  51.2 ,  51.2 ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,  64.  ,  51.2 ,   0.  ,  80.  ,  64.  ,   0.  ,\n",
       "         51.2 ,   0.  ,   0.  ,   0.  ,   0.  ,  51.2 ,  51.2 ,  51.2 ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,  64.  ,  51.2 ,   0.  ,   0.  ,   0.  ,  64.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  51.2 ,  51.2 ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,  80.  ,  80.  ,  64.  ,   0.  ,\n",
       "          0.  , 100.  ,   0.  ,  64.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         80.  ,  80.  ,  64.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  80.  ,  64.  ,   0.  ,\n",
       "          0.  ,   0.  ,  80.  ,   0.  ,  51.2 ,  51.2 ,   0.  ,   0.  ,\n",
       "          0.  ,  80.  ,  64.  ,  51.2 ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  64.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,  64.  ,   0.  ,  51.2 ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,  64.  ,  51.2 ,  40.96,  40.96,  40.96,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  64.  ,  64.  ,\n",
       "          0.  ,   0.  ,   0.  ,  64.  ,  51.2 ,   0.  ,  51.2 ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  40.96,  40.96,  40.96,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  64.  ,  64.  ,\n",
       "         51.2 ,   0.  ,   0.  ,   0.  ,   0.  ,  51.2 ,   0.  ,  51.2 ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  40.96,  40.96,\n",
       "         40.96],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  64.  ,\n",
       "         51.2 ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  51.2 ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  40.96,\n",
       "         40.96],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  , 100.  ,  80.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,  80.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  , 100.  ,  80.  ,  64.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         80.  ,   0.  ,  64.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,  80.  ,  64.  ,  51.2 ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,  80.  ,   0.  ,  51.2 ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,  64.  ,  51.2 ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,  64.  ,   0.  ,  40.96,  40.96,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,  51.2 ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,  51.2 ,   0.  ,  40.96,   0.  ,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,  51.2 ,  51.2 ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,  51.2 ,  40.96,   0.  ,  40.96,   0.  ,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,  51.2 ,  51.2 ,  51.2 ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  40.96,   0.  ,  40.96,\n",
       "          0.  ],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  51.2 ,  51.2 ,  51.2 ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  40.96,   0.  ,\n",
       "         40.96],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  51.2 ,  51.2 ,\n",
       "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  40.96,\n",
       "          0.  ]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qq = entrenarQ(qMatrix, rMatrix, 0.8, objetivo, 500)\n",
    "Qq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Normalizamos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "qMatrix=(qMatrix/np.max(qMatrix))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obteniendo así la matriz __Q__ entrenada y normalizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camino eficiente\n",
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Último paso será pues, obtener el camino más eficiente hacia el __estado objetivo__ siendo una lista con los estados que llevan desde el __estado inicial__ hasta el objetivo.\n",
    "\n",
    "Para su ejecución simplemente tendríamos que observar cuál es la acción que nos ofrece una mayor recompensa para cada estado, buscando en la matriz Q. Incluyendo así los estados visitados en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOptimalWay(initialState, Q, objetive):\n",
    "    #paso1 \n",
    "    actualState = initialState\n",
    "    camino = [initialState]\n",
    "    contador=0\n",
    "    totalValue=0\n",
    "    #paso2\n",
    "    while(actualState!=objetive):\n",
    "        qRow = Q[actualState]\n",
    "        maxValue = np.max(qRow)\n",
    "        maxValueIndex = np.where(qRow == maxValue)\n",
    "        nextState=maxValueIndex[0][0]\n",
    "        camino.append(nextState)\n",
    "        #paso3\n",
    "        totalValue += maxValue \n",
    "        actualState=nextState\n",
    "        print(actualState)\n",
    "        contador=contador+1\n",
    "    return camino, contador, totalValue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "[camino,contador,totalValue]=findOptimalWay(8, qMatrix, objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 2, 4, 9]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
